{"items": [{"owner": {"account_id": 37442, "reputation": 102557, "user_id": 107049, "user_type": "registered", "accept_rate": 75, "profile_image": "https://www.gravatar.com/avatar/b1f458499807b5dbd4019bfc9714f644?s=256&d=identicon&r=PG", "display_name": "Thomasleveil", "link": "https://stackoverflow.com/users/107049/thomasleveil"}, "is_accepted": true, "score": 4748, "last_activity_date": 1679696391, "last_edit_date": 1679696391, "creation_date": 1403264811, "answer_id": 24326540, "question_id": 24319662, "content_license": "CC BY-SA 4.0", "body": "<p><strong>Edit:</strong></p>\n<p>If you are using <a href=\"https://docs.docker.com/docker-for-mac/networking/#there-is-no-docker0-bridge-on-macos#i-want-to-connect-from-a-container-to-a-service-on-the-host\" rel=\"noreferrer\">Docker-for-mac</a> or <a href=\"https://docs.docker.com/docker-for-windows/networking/#there-is-no-docker0-bridge-on-windows#i-want-to-connect-from-a-container-to-a-service-on-the-host\" rel=\"noreferrer\">Docker-for-Windows</a> 18.03+, connect to your mysql service using the host <code>host.docker.internal</code> (instead of the <code>127.0.0.1</code> in your connection string).</p>\n<p>If you are using <strong>Docker-for-Linux</strong> 20.10.0+, you can also use the host <code>host.docker.internal</code> <strong>if</strong> you started your Docker container with the <code>--add-host host.docker.internal:host-gateway</code> option, or added the following snippet in your docker-compose.yml file :</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>extra_hosts:\n    - &quot;host.docker.internal:host-gateway&quot;\n</code></pre>\n<p>Otherwise, read below</p>\n<hr />\n<h2>TLDR</h2>\n<p>Use <code>--network=&quot;host&quot;</code> in your <code>docker run</code> command, then <code>127.0.0.1</code> in your docker container will point to your docker host.</p>\n<p>Note: This mode only works on Docker for Linux, <a href=\"https://docs.docker.com/network/host/\" rel=\"noreferrer\">per the documentation</a>.</p>\n<hr />\n<h1>Note on docker container networking modes</h1>\n<p>Docker offers <a href=\"https://docs.docker.com/engine/reference/run/#network-settings\" rel=\"noreferrer\">different networking modes</a> when running containers. Depending on the mode you choose you would connect to your MySQL database running on the docker host differently.</p>\n<h2>docker run --network=&quot;bridge&quot; (default)</h2>\n<p>Docker creates a bridge named <code>docker0</code> by default. Both the docker host and the docker containers have an IP address on that bridge.</p>\n<p>on the Docker host, type <code>sudo ip addr show docker0</code> you will have an output looking like:</p>\n<pre><code>[vagrant@docker:~] $ sudo ip addr show docker0\n4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default\n    link/ether 56:84:7a:fe:97:99 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.42.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::5484:7aff:fefe:9799/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n<p>So here my docker host has the IP address <code>172.17.42.1</code> on the <code>docker0</code> network interface.</p>\n<p>Now start a new container and get a shell on it: <code>docker run --rm -it ubuntu:trusty bash</code> and within the container type <code>ip addr show eth0</code> to discover how its main network interface is set up:</p>\n<pre><code>root@e77f6a1b3740:/# ip addr show eth0\n863: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 66:32:13:f0:f1:e3 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.1.192/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::6432:13ff:fef0:f1e3/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n<p>Here my container has the IP address <code>172.17.1.192</code>. Now look at the routing table:</p>\n<pre><code>root@e77f6a1b3740:/# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         172.17.42.1     0.0.0.0         UG    0      0        0 eth0\n172.17.0.0      *               255.255.0.0     U     0      0        0 eth0\n</code></pre>\n<p>So the IP Address of the docker host <code>172.17.42.1</code> is set as the default route and is accessible from your container.</p>\n<pre><code>root@e77f6a1b3740:/# ping 172.17.42.1\nPING 172.17.42.1 (172.17.42.1) 56(84) bytes of data.\n64 bytes from 172.17.42.1: icmp_seq=1 ttl=64 time=0.070 ms\n64 bytes from 172.17.42.1: icmp_seq=2 ttl=64 time=0.201 ms\n64 bytes from 172.17.42.1: icmp_seq=3 ttl=64 time=0.116 ms\n</code></pre>\n<h2>docker run --network=&quot;host&quot;</h2>\n<p>Alternatively you can run a docker container with <a href=\"http://docs.docker.com/engine/reference/run/#network-host\" rel=\"noreferrer\">network settings set to <code>host</code></a>. Such a container will share the network stack with the docker host and from the container point of view, <code>localhost</code> (or <code>127.0.0.1</code>) will refer to the docker host.</p>\n<p>Be aware that any port opened in your docker container would be opened on the docker host. And this without requiring the <a href=\"https://docs.docker.com/engine/reference/run/#expose-incoming-ports\" rel=\"noreferrer\"><code>-p</code> or <code>-P</code> <code>docker run</code> option</a>.</p>\n<p>IP config on my docker host:</p>\n<pre><code>[vagrant@docker:~] $ ip addr show eth0\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n<p>and from a docker container in <strong>host</strong> mode:</p>\n<pre><code>[vagrant@docker:~] $ docker run --rm -it --network=host ubuntu:trusty ip addr show eth0\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n<p>As you can see both the docker host and docker container share the exact same network interface and as such have the same IP address.</p>\n<hr />\n<h1>Connecting to MySQL from containers</h1>\n<h2>bridge mode</h2>\n<p>To access MySQL running on the docker host from containers in <em>bridge mode</em>, you need to make sure the MySQL service is listening for connections on the <code>172.17.42.1</code> IP address.</p>\n<p>To do so, make sure you have either <code>bind-address = 172.17.42.1</code> or <code>bind-address = 0.0.0.0</code> in your MySQL config file (my.cnf).</p>\n<p>If you need to set an environment variable with the IP address of the gateway, you can run the following code in a container :</p>\n<pre><code>export DOCKER_HOST_IP=$(route -n | awk '/UG[ \\t]/{print $2}')\n</code></pre>\n<p>then in your application, use the <code>DOCKER_HOST_IP</code> environment variable to open the connection to MySQL.</p>\n<p><strong>Note:</strong> if you use <code>bind-address = 0.0.0.0</code> your MySQL server will listen for connections on all network interfaces. That means your MySQL server could be reached from the Internet ; make sure to set up firewall rules accordingly.</p>\n<p><strong>Note 2:</strong> if you use <code>bind-address = 172.17.42.1</code> your MySQL server won't listen for connections made to <code>127.0.0.1</code>. Processes running on the docker host that would want to connect to MySQL would have to use the <code>172.17.42.1</code> IP address.</p>\n<h2>host mode</h2>\n<p>To access MySQL running on the docker host from containers in <em>host mode</em>, you can keep <code>bind-address = 127.0.0.1</code> in your MySQL configuration and connect to <code>127.0.0.1</code> from your containers:</p>\n<pre><code>[vagrant@docker:~] $ docker run --rm -it --network=host mysql mysql -h 127.0.0.1 -uroot -p\nEnter password:\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 36\nServer version: 5.5.41-0ubuntu0.14.04.1 (Ubuntu)\n\nCopyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql&gt;\n</code></pre>\n<p><strong>note:</strong> Do use <code>mysql -h 127.0.0.1</code> and not <code>mysql -h localhost</code>; otherwise the MySQL client would try to connect using a unix socket.</p>\n"}, {"owner": {"account_id": 474951, "reputation": 120344, "user_id": 884978, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/bdb4f5f287976278b6e02f66e85c41dc?s=256&d=identicon&r=PG", "display_name": "creack", "link": "https://stackoverflow.com/users/884978/creack"}, "is_accepted": true, "score": 4697, "last_activity_date": 1573140350, "last_edit_date": 1573140350, "creation_date": 1393439500, "answer_id": 22050116, "question_id": 22049212, "content_license": "CC BY-SA 4.0", "body": "<p>In order to copy a file from a container to the host, you can use the command</p>\n\n<pre><code>docker cp &lt;containerId&gt;:/file/path/within/container /host/path/target\n</code></pre>\n\n<p>Here's an example:</p>\n\n<pre><code>$ sudo docker cp goofy_roentgen:/out_read.jpg .\n</code></pre>\n\n<p>Here <strong>goofy_roentgen</strong> is the container name I got from the following command:</p>\n\n<pre><code>$ sudo docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                                            NAMES\n1b4ad9311e93        bamos/openface      \"/bin/bash\"         33 minutes ago      Up 33 minutes       0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp   goofy_roentgen\n</code></pre>\n\n<p>You can also use (part of) the <strong>Container ID</strong>. The following command is equivalent to the first</p>\n\n<pre><code>$ sudo docker cp 1b4a:/out_read.jpg .\n</code></pre>\n"}, {"owner": {"account_id": 3205277, "reputation": 53504, "user_id": 2706422, "user_type": "registered", "accept_rate": 100, "profile_image": "https://i.sstatic.net/iAdRu.jpg?s=256", "display_name": "Henrik Sachse", "link": "https://stackoverflow.com/users/2706422/henrik-sachse"}, "is_accepted": true, "score": 4109, "last_activity_date": 1631118379, "last_edit_date": 1631118379, "creation_date": 1439400300, "answer_id": 31971697, "question_id": 22907231, "content_license": "CC BY-SA 4.0", "body": "<p>The <code>cp</code> command can be used to copy files.</p>\n<p>One specific file can be copied TO the container like:</p>\n<pre><code>docker cp foo.txt container_id:/foo.txt\n</code></pre>\n<p>One specific file can be copied FROM the container like:</p>\n<pre><code>docker cp container_id:/foo.txt foo.txt\n</code></pre>\n<p>For emphasis, <code>container_id</code> is a <em>container</em> ID, <strong>not</strong> an <em>image</em> ID. (Use <code>docker ps</code> to view listing which includes <code>container_id</code>s.)</p>\n<p>Multiple files contained by the folder <code>src</code> can be copied into the <code>target</code> folder using:</p>\n<pre><code>docker cp src/. container_id:/target\ndocker cp container_id:/src/. target\n</code></pre>\n<p>Reference: <a href=\"https://docs.docker.com/engine/reference/commandline/cp/\" rel=\"noreferrer\">Docker CLI docs for <code>cp</code></a></p>\n<p>In Docker versions prior to 1.8 it was only possible to copy files from a container to the host. Not from the host to a container.</p>\n"}, {"owner": {"account_id": 146372, "reputation": 76897, "user_id": 356788, "user_type": "registered", "accept_rate": 43, "profile_image": "https://www.gravatar.com/avatar/5b5661a3a443a2a4bece8674006bd6ef?s=256&d=identicon&r=PG", "display_name": "Ken Cochrane", "link": "https://stackoverflow.com/users/356788/ken-cochrane"}, "is_accepted": true, "score": 4019, "last_activity_date": 1574191770, "last_edit_date": 1574191770, "creation_date": 1366151727, "answer_id": 16048358, "question_id": 16047306, "content_license": "CC BY-SA 4.0", "body": "<p>Docker originally used <a href=\"https://linuxcontainers.org/lxc/\" rel=\"noreferrer\">LinuX Containers</a> (LXC), but later switched to <a href=\"https://github.com/opencontainers/runc\" rel=\"noreferrer\">runC</a> (formerly known as <strong>libcontainer</strong>), which runs in the same operating system as its host. This allows it to share a lot of the host operating system resources. Also, it uses a layered filesystem (<a href=\"http://aufs.sourceforge.net/\" rel=\"noreferrer\">AuFS</a>) and manages networking.</p>\n\n<p>AuFS is a layered file system, so you can have a read only part and a write part which are merged together. One could have the common parts of the operating system as read only (and shared amongst all of your containers) and then give each container its own mount for writing.</p>\n\n<p>So, let's say you have a 1&nbsp;GB container image; if you wanted to use a full VM, you would need to have 1&nbsp;GB x number of VMs you want. With Docker and AuFS you can share the bulk of the 1&nbsp;GB between all the containers and if you have 1000 containers you still might only have a little over 1&nbsp;GB of space for the containers OS (assuming they are all running the same OS image).</p>\n\n<p>A full virtualized system gets its own set of resources allocated to it, and does minimal sharing. You get more isolation, but it is much heavier (requires more resources). With Docker you get less isolation, but the containers are lightweight (require fewer resources). So you could easily run thousands of containers on a host, and it won't even blink. Try doing that with Xen, and unless you have a really big host, I don't think it is possible.</p>\n\n<p>A full virtualized system usually takes minutes to start, whereas Docker/LXC/runC containers take seconds, and often even less than a second.</p>\n\n<p>There are pros and cons for each type of virtualized system. If you want full isolation with guaranteed resources, a full VM is the way to go. If you just want to isolate processes from each other and want to run a ton of them on a reasonably sized host, then Docker/LXC/runC seems to be the way to go.</p>\n\n<p>For more information, check out <a href=\"http://web.archive.org/web/20150326185901/http://blog.dotcloud.com/under-the-hood-linux-kernels-on-dotcloud-part\" rel=\"noreferrer\">this set of blog posts</a> which do a good job of explaining how LXC works.</p>\n\n<blockquote>\n  <p>Why is deploying software to a docker image (if that's the right term) easier than simply deploying to a consistent production environment?</p>\n</blockquote>\n\n<p>Deploying a consistent production environment is easier said than done. Even if you use tools like <a href=\"https://en.wikipedia.org/wiki/Chef_%28software%29\" rel=\"noreferrer\">Chef</a> and <a href=\"https://en.wikipedia.org/wiki/Puppet_%28software%29\" rel=\"noreferrer\">Puppet</a>, there are always OS updates and other things that change between hosts and environments.</p>\n\n<p>Docker gives you the ability to snapshot the OS into a shared image, and makes it easy to deploy on other Docker hosts. Locally, dev, qa, prod, etc.: all the same image. Sure you can do this with other tools, but not nearly as easily or fast.</p>\n\n<p>This is great for testing; let's say you have thousands of tests that need to connect to a database, and each test needs a pristine copy of the database and will make changes to the data. The classic approach to this is to reset the database after every test either with custom code or with tools like <a href=\"https://flywaydb.org/\" rel=\"noreferrer\">Flyway</a> - this can be very time-consuming and means that tests must be run serially. However, with Docker you could create an image of your database and run up one instance per test, and then run all the tests in parallel since you know they will all be running against the same snapshot of the database. Since the tests are running in parallel and in Docker containers they could run all on the same box at the same time and should finish much faster. Try doing that with a full VM.</p>\n\n<p>From comments...</p>\n\n<blockquote>\n  <p>Interesting! I suppose I'm still confused by the notion of \"snapshot[ting] the OS\". How does one do that without, well, making an image of the OS?</p>\n</blockquote>\n\n<p>Well, let's see if I can explain. You start with a base image, and then make your changes, and commit those changes using docker, and it creates an image. This image contains only the differences from the base. When you want to run your image, you also need the base, and it layers your image on top of the base using a layered file system: as mentioned above, Docker uses AuFS. AuFS merges the different layers together and you get what you want; you just need to run it. You can keep adding more and more images (layers) and it will continue to only save the diffs. Since Docker typically builds on top of ready-made images from a <a href=\"https://registry.hub.docker.com/\" rel=\"noreferrer\">registry</a>, you rarely have to \"snapshot\" the whole OS yourself.</p>\n"}, {"owner": {"account_id": 1680161, "reputation": 42896, "user_id": 1544590, "user_type": "registered", "accept_rate": 76, "profile_image": "https://www.gravatar.com/avatar/cdb57618cf028c2a58191b7396a1fbe0?s=256&d=identicon&r=PG", "display_name": "Daiwei", "link": "https://stackoverflow.com/users/1544590/daiwei"}, "is_accepted": true, "score": 3779, "last_activity_date": 1709313090, "last_edit_date": 1709313090, "creation_date": 1401383392, "answer_id": 23938978, "question_id": 23935141, "content_license": "CC BY-SA 4.0", "body": "<p>You will need to save the Docker image as a tar file:</p>\n<pre><code>docker save -o &lt;path for generated tar file&gt; &lt;image name&gt;\n</code></pre>\n<p>Then copy your image to a new system with regular file transfer tools such as <code>cp</code>, <code>scp</code>, or <code>rsync</code> (preferred for big files). After that you will have to load the image into Docker:</p>\n<pre><code>docker load -i &lt;path to image tar file&gt;\n</code></pre>\n<p>You should add filename (not just directory) with -o, for example:</p>\n<pre><code>docker save -o c:/myfile.tar centos:16\n</code></pre>\n<p>your image syntax may need the repository prefix (:latest tag is default)</p>\n<pre><code>docker save -o C:\\path\\to\\file.tar repository/imagename\n</code></pre>\n<hr />\n<p>PS: You may need to <code>sudo</code> all commands.</p>\n"}, {"owner": {"account_id": 3752694, "reputation": 36896, "user_id": 3119830, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/17296d7b0c21c38bbe7c50371547f11b?s=256&d=identicon&r=PG", "display_name": "WouterD", "link": "https://stackoverflow.com/users/3119830/wouterd"}, "is_accepted": true, "score": 3641, "last_activity_date": 1686748290, "last_edit_date": 1686748290, "creation_date": 1387468581, "answer_id": 20686101, "question_id": 17157721, "content_license": "CC BY-SA 4.0", "body": "<p>This solution only works if the container is connected with a single network. The <code>--format</code> option of <code>inspect</code> comes to the rescue.</p>\n<p>Modern Docker client syntax is:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>docker inspect \\\n  -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container_name_or_id\n</code></pre>\n<p>Old Docker client syntax is:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>docker inspect \\\n  --format '{{ .NetworkSettings.IPAddress }}' container_name_or_id\n</code></pre>\n<p>These commands will return the Docker container's IP address.</p>\n<p>As mentioned in the comments: if you are on Windows, use double quotes <code>&quot;</code> instead of single quotes <code>'</code> around the curly braces.</p>\n"}, {"owner": {"account_id": 49492, "reputation": 304625, "user_id": 147356, "user_type": "registered", "accept_rate": 54, "profile_image": "https://www.gravatar.com/avatar/b9506717d24256a090524dd5505d3207?s=256&d=identicon&r=PG", "display_name": "larsks", "link": "https://stackoverflow.com/users/147356/larsks"}, "is_accepted": true, "score": 3134, "last_activity_date": 1722007997, "last_edit_date": 1722007997, "creation_date": 1431362692, "answer_id": 30173220, "question_id": 30172605, "content_license": "CC BY-SA 4.0", "body": "<p><code>docker attach</code> will let you connect to your Docker container, but this isn't really the same thing as <code>ssh</code>.  If your container is running a webserver, for example, <code>docker attach</code> will probably connect you to the <em>stdout</em> of the web server process.  It won't necessarily give you a shell.</p>\n<p>The <code>docker exec</code> command is probably what you are looking for; this will let you run arbitrary commands inside an existing container.  For example, to run <code>bash</code> inside a container:</p>\n<pre><code>docker exec -it &lt;mycontainer&gt; sh\n</code></pre>\n<p>Of course, whatever command you are running must exist in the container filesystem; if your container doesn't have <code>sh</code>, this will fail with something like:</p>\n<pre><code>OCI runtime exec failed: exec failed: unable to start container process:\nexec: &quot;sh&quot;: executable file not found in $PATH: unknown\n</code></pre>\n<p>[If your container doesn't have <code>sh</code> -- which is a common case for minimal images -- you may need to investigate other ways to explore the container filesystem.]</p>\n<p>In the above command <code>&lt;mycontainer&gt;</code> is the name or ID of the target container.  It doesn't matter whether or not you're using <code>docker compose</code>; just run <code>docker ps</code> and use either the ID (a hexadecimal string displayed in the first column) or the name (displayed in the final column).  E.g., given:</p>\n<pre><code>$ docker ps\nd2d4a89aaee9        larsks/mini-httpd   &quot;mini_httpd -d /cont   7 days ago          Up 7 days                               web                 \n</code></pre>\n<p>I can run:</p>\n<pre><code>$ docker exec -it web ip addr\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN \n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n18: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.3/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:acff:fe11:3/64 scope link \n       valid_lft forever preferred_lft forever\n</code></pre>\n<p>I could accomplish the same thing by running:</p>\n<pre><code>$ docker exec -it d2d4a89aaee9 ip addr\n</code></pre>\n<p>Similarly, I could start a shell in the container;</p>\n<pre><code>$ docker exec -it web sh\n/ # echo This is inside the container.\nThis is inside the container.\n/ # exit\n$\n</code></pre>\n<hr />\n<p>In commands shown in this answer, the <code>-i</code> and <code>-t</code> options (combined as <code>-it</code>) are necessary to get an interactive shell:</p>\n<ul>\n<li><p><code>-i</code> keeps <em>stdin</em> connected; if you don't specify <code>-i</code>, the shell will simply exit.</p>\n</li>\n<li><p><code>-t</code> allocates a tty device; if you don't specify <code>-t</code>, you won't have a very pleasant interactive experience (there will be no shell prompt or job control, for example).</p>\n</li>\n</ul>\n<hr />\n<p>If you're specifically using <code>docker compose</code>, there is a convenience <code>docker compose exec</code> command that works very much like the <code>docker exec</code> command, except:</p>\n<ul>\n<li>It defaults to the behavior of <code>-i</code> and <code>-t</code></li>\n<li>It allows you to refer to containers by their service name in your <code>compose.yaml</code> file.</li>\n</ul>\n<p>For example, if you have a <code>compose.yaml</code> like this:</p>\n<pre><code>services:\n  web:\n    image: docker.io/alpinelinux/darkhttpd\n</code></pre>\n<p>Then you can run:</p>\n<pre><code>docker compose exec web sh\n</code></pre>\n<p>The equivalent <code>docker exec</code> command would be something like:</p>\n<pre><code>docker exec -it myproject-web-1 sh\n</code></pre>\n"}, {"owner": {"account_id": 204016, "reputation": 76315, "user_id": 451980, "user_type": "registered", "accept_rate": 75, "profile_image": "https://www.gravatar.com/avatar/1841c9660d949d4f975ab3abd02a953f?s=256&d=identicon&r=PG", "display_name": "icecrime", "link": "https://stackoverflow.com/users/451980/icecrime"}, "is_accepted": true, "score": 2972, "last_activity_date": 1698708253, "last_edit_date": 1698708253, "creation_date": 1406299958, "answer_id": 24958548, "question_id": 24958140, "content_license": "CC BY-SA 4.0", "body": "<p>You should check the <a href=\"https://docs.docker.com/engine/reference/builder/#add\" rel=\"noreferrer\"><code>ADD</code></a> and <a href=\"https://docs.docker.com/engine/reference/builder/#copy\" rel=\"noreferrer\"><code>COPY</code></a> documentation for a more detailed description of their behaviors, but in a nutshell, the major difference is that <code>ADD</code> can do more than <code>COPY</code>:</p>\n<ul>\n<li><code>ADD</code> allows <code>&lt;src&gt;</code> to be a URL</li>\n<li>Referring to comments below, the <code>ADD</code> <a href=\"https://docs.docker.com/engine/reference/builder/#add\" rel=\"noreferrer\">documentation</a> states that:</li>\n</ul>\n<blockquote>\n<p>If  is a local tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from remote URLs are not decompressed.</p>\n</blockquote>\n<p>Note that the <a href=\"https://docs.docker.com/develop/develop-images/instructions/#add-or-copy\" rel=\"noreferrer\">Best practices for writing Dockerfiles</a> suggests using <code>COPY</code> where the magic of <code>ADD</code> is not required. Otherwise, you (<em>since you had to look up this answer</em>) are likely to get surprised someday when you mean to copy <code>keep_this_archive_intact.tar.gz</code> into your container, but instead, you spray the contents onto your filesystem.</p>\n"}, {"owner": {"account_id": 6619, "reputation": 75313, "user_id": 11208, "user_type": "registered", "accept_rate": 70, "profile_image": "https://i.sstatic.net/jkSDT.jpg?s=256", "display_name": "Assaf Lavie", "link": "https://stackoverflow.com/users/11208/assaf-lavie"}, "is_accepted": true, "score": 2677, "last_activity_date": 1532446680, "last_edit_date": 1532446680, "creation_date": 1456296031, "answer_id": 35595021, "question_id": 35594987, "content_license": "CC BY-SA 4.0", "body": "<p>There's a <code>--no-cache</code> option:</p>\n\n<pre><code>docker build --no-cache -t u12_core -f u12_core .\n</code></pre>\n\n<p>In older versions of Docker you needed to pass <code>--no-cache=true</code>, but this is no longer the case.</p>\n"}, {"owner": {"account_id": 474951, "reputation": 120344, "user_id": 884978, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/bdb4f5f287976278b6e02f66e85c41dc?s=256&d=identicon&r=PG", "display_name": "creack", "link": "https://stackoverflow.com/users/884978/creack"}, "is_accepted": true, "score": 2664, "last_activity_date": 1645170405, "last_edit_date": 1645170405, "creation_date": 1391553273, "answer_id": 21564990, "question_id": 21553353, "content_license": "CC BY-SA 4.0", "body": "<p>Docker has a default entrypoint which is <code>/bin/sh -c</code> but does not have a default command.</p>\n<p>When you run docker like this:\n<code>docker run -i -t ubuntu bash</code>\nthe entrypoint is the default <code>/bin/sh -c</code>, the image is <code>ubuntu</code> and the command is <code>bash</code>.</p>\n<p>The command is run via the entrypoint. i.e., the actual thing that gets executed is <code>/bin/sh -c bash</code>. This allowed Docker to implement <code>RUN</code> quickly by relying on the shell's parser.</p>\n<p>Later on, people asked to be able to customize this, so <code>ENTRYPOINT</code> and <code>--entrypoint</code> were introduced.</p>\n<p>Everything after the image name, <code>ubuntu</code> in the example above, is the command and is passed to the entrypoint. When using the <code>CMD</code> instruction, it is exactly as if you were executing<br />\n<code>docker run -i -t ubuntu &lt;cmd&gt;</code><br />\nThe parameter of the entrypoint is <code>&lt;cmd&gt;</code>.</p>\n<p>You will also get the same result if you instead type this command <code>docker run -i -t ubuntu</code>: a bash shell will start in the container because in the <a href=\"https://github.com/dockerfile/ubuntu/blob/master/Dockerfile\" rel=\"noreferrer\">ubuntu Dockerfile</a> a default <code>CMD</code> is specified:<br />\n<code>CMD [&quot;bash&quot;]</code>.</p>\n<p>As everything is passed to the entrypoint, you can have a very nice behavior from your images. @Jiri example is good, it shows how to use an image as a &quot;binary&quot;. When using <code>[&quot;/bin/cat&quot;]</code> as entrypoint and then doing <code>docker run img /etc/passwd</code>, you get it, <code>/etc/passwd</code> is the command and is passed to the entrypoint so the end result execution is simply <code>/bin/cat /etc/passwd</code>.</p>\n<p>Another example would be to have any cli as entrypoint. For instance, if you have a redis image, instead of running <code>docker run redisimg redis -H something -u toto get key</code>, you can simply have <code>ENTRYPOINT [&quot;redis&quot;, &quot;-H&quot;, &quot;something&quot;, &quot;-u&quot;, &quot;toto&quot;]</code> and then run like this for the same result: <code>docker run redisimg get key</code>.</p>\n"}, {"owner": {"account_id": 5233, "reputation": 32999, "user_id": 8325, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/54079122b67de9677c1f93933ce8b63a?s=256&d=identicon&r=PG", "display_name": "Mitchell", "link": "https://stackoverflow.com/users/8325/mitchell"}, "is_accepted": false, "score": 2425, "last_activity_date": 1455928180, "last_edit_date": 1455928180, "creation_date": 1390496152, "answer_id": 21314566, "question_id": 16647069, "content_license": "CC BY-SA 3.0", "body": "<p><em>Disclaimer: I wrote Vagrant! But because I wrote Vagrant, I spend most of my time living in the DevOps world which includes software like Docker. I work with a lot of companies using Vagrant and many use Docker, and I see how the two interplay.</em></p>\n\n<p><strong>Before I talk too much, a direct answer:</strong> in your specific scenario (yourself working alone, working on Linux, using Docker in production), you can stick with Docker alone and simplify things. In many other scenarios (I discuss further), it isn't so easy.</p>\n\n<p>It isn't correct to directly compare Vagrant to Docker. In some scenarios, they do overlap, and in the vast majority, they don't. Actually, the more apt comparison would be Vagrant versus something like Boot2Docker (minimal OS that can run Docker). Vagrant is a level above Docker in terms of abstractions, so it isn't a fair comparison in most cases.</p>\n\n<p>Vagrant launches things to run apps/services for the purpose of development. This can be on VirtualBox, VMware. It can be remote like AWS, OpenStack. Within those, if you use containers, Vagrant doesn't care, and embraces that: it can automatically install, pull down, build, and run Docker containers, for example. With Vagrant 1.6, Vagrant has <a href=\"http://www.vagrantup.com/blog/feature-preview-vagrant-1-6-docker-dev-environments.html\">docker-based development environments</a>, and supports using Docker with the same workflow as Vagrant across Linux, Mac, and Windows. Vagrant doesn't try to replace Docker here, it embraces Docker practices.</p>\n\n<p>Docker specifically runs Docker containers. If you're comparing directly to Vagrant: it is specifically a more specific (can only run Docker containers), less flexible (requires Linux or Linux host somewhere) solution. Of course if you're talking about production or CI, there is no comparison to Vagrant! Vagrant doesn't live in these environments, and so Docker should be used. </p>\n\n<p>If your organization runs only Docker containers for all their projects and only has developers running on Linux, then okay, Docker could definitely work for you! </p>\n\n<p>Otherwise, I don't see a benefit to attempting to use Docker alone, since you lose a lot of what Vagrant has to offer, which have real business/productivity benefits:</p>\n\n<ul>\n<li><p>Vagrant can launch VirtualBox, VMware, AWS, OpenStack, etc. machines. It doesn't matter what you need, Vagrant can launch it. If you are using Docker, Vagrant can install Docker on any of these so you can use them for that purpose.</p></li>\n<li><p>Vagrant is a single workflow for all your projects. Or to put another way, it is just one thing people have to learn to run a project whether it is in a Docker container or not. If, for example, in the future, a competitor arises to compete directly with Docker, Vagrant will be able to run that too. </p></li>\n<li><p>Vagrant works on Windows (back to XP), Mac (back to 10.5), and Linux (back to kernel 2.6). In all three cases, the workflow is the same. If you use Docker, Vagrant can launch a machine (VM or remote) that can run Docker on all three of these systems.</p></li>\n<li><p>Vagrant knows how to configure some advanced or non-trivial things like networking and syncing folders. For example: Vagrant knows how to attach a static IP to a machine or forward ports, and the configuration is the same no matter what system you use (VirtualBox, VMware, etc.) For synced folders, Vagrant provides multiple mechanisms to get your local files over to the remote machine (VirtualBox shared folders, NFS, rsync, Samba [plugin], etc.). If you're using Docker, even Docker with a VM without Vagrant, you would have to manually do this or they would have to reinvent Vagrant in this case.</p></li>\n<li><p>Vagrant 1.6 has first-class support for <a href=\"http://www.vagrantup.com/blog/feature-preview-vagrant-1-6-docker-dev-environments.html\">docker-based development environments</a>. This will not launch a virtual machine on Linux, and will automatically launch a virtual machine on Mac and Windows. The end result is that working with Docker is uniform across all platforms, while Vagrant still handles the tedious details of things such as networking, synced folders, etc.</p></li>\n</ul>\n\n<p>To address specific counter arguments that I've heard in favor of using Docker instead of Vagrant:</p>\n\n<ul>\n<li><p>\"It is less moving parts\" - Yes, it can be, if you use Docker exclusively for every project. Even then, it is sacrificing flexibility for Docker lock-in. If you ever decide to not use Docker for any project, past, present, or future, then you'll have more moving parts. If you had used Vagrant, you have that one moving part that supports the rest.</p></li>\n<li><p>\"It is faster!\" - Once you have the host that can run Linux containers, Docker is definitely faster at running a container than any virtual machine would be to launch. But launching a virtual machine (or remote machine) is a one-time cost. Over the course of the day, most Vagrant users never actually destroy their VM. It is a strange optimization for development environments. In production, where Docker really shines, I understand the need to quickly spin up/down containers.</p></li>\n</ul>\n\n<p>I hope now its clear to see that it is very difficult, and I believe not correct, to compare Docker to Vagrant. For dev environments, Vagrant is more abstract, more general. Docker (and the various ways you can make it behave like Vagrant) is a specific use case of Vagrant, ignoring everything else Vagrant has to offer. </p>\n\n<p>In conclusion: in highly specific use cases, Docker is certainly a possible replacement for Vagrant. In most use cases, it is not. Vagrant doesn't hinder your usage of Docker; it actually does what it can to make that experience smoother. If you find this isn't true, I'm happy to take suggestions to improve things, since a goal of Vagrant is to work equally well with any system.</p>\n\n<p>Hope this clears things up!</p>\n"}, {"owner": {"account_id": 5508729, "reputation": 23698, "user_id": 4375823, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/b12d25d2a99a6725ef59e45556b7f442?s=256&d=identicon&r=PG&f=y&so-version=2", "display_name": "mkb", "link": "https://stackoverflow.com/users/4375823/mkb"}, "is_accepted": true, "score": 2334, "last_activity_date": 1684375843, "last_edit_date": 1684375843, "creation_date": 1519429215, "answer_id": 48957722, "question_id": 48957195, "content_license": "CC BY-SA 4.0", "body": "<p>If you want to run docker as non-root user then you need to add it to the docker group.</p>\n\n<ol>\n<li>Create the docker group if it does not exist</li>\n</ol>\n<pre class=\"lang-bash prettyprint-override\"><code>$ sudo groupadd docker\n</code></pre>\n<ol start=\"2\">\n<li>Add your user to the docker group.</li>\n</ol>\n<pre class=\"lang-bash prettyprint-override\"><code>$ sudo usermod -aG docker $USER\n</code></pre>\n<ol start=\"3\">\n<li>Log in to the new <code>docker</code> group (to avoid having to log out / log in again; but if not enough, try to reboot):</li>\n</ol>\n<pre class=\"lang-bash prettyprint-override\"><code>$ newgrp docker\n</code></pre>\n<ol start=\"4\">\n<li>Check if docker can be run without root</li>\n</ol>\n<pre class=\"lang-bash prettyprint-override\"><code>$ docker run hello-world\n</code></pre>\n<p>Reboot if still got error</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ reboot\n</code></pre>\n<p><strong>Warning</strong></p>\n<blockquote>\n<p>The docker group grants privileges equivalent to the root user. For details on how this impacts security in your system, see <a href=\"https://docs.docker.com/engine/security/#docker-daemon-attack-surface\" rel=\"noreferrer\">Docker Daemon Attack Surface.</a>.</p>\n</blockquote>\n<p>Taken from the docker official documentation:\n<a href=\"https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user\" rel=\"noreferrer\">manage-docker-as-a-non-root-user</a></p>\n"}, {"owner": {"account_id": 1309411, "reputation": 26103, "user_id": 1257729, "user_type": "registered", "profile_image": "https://i.sstatic.net/gHxSN.jpg?s=256", "display_name": "techtabu", "link": "https://stackoverflow.com/users/1257729/techtabu"}, "is_accepted": true, "score": 2243, "last_activity_date": 1721658780, "last_edit_date": 1721658780, "creation_date": 1498582126, "answer_id": 44785784, "question_id": 44785585, "content_license": "CC BY-SA 4.0", "body": "<p><strong>Unix</strong></p>\n<p>To delete all containers including its volumes use,</p>\n\n<pre class=\"lang-bash prettyprint-override\"><code>docker rm -vf $(docker ps -aq)\n</code></pre>\n<p>To delete all the images,</p>\n<pre class=\"lang-bash prettyprint-override\"><code>docker rmi -f $(docker images -aq)\n</code></pre>\n<p>Remember, you should remove all the containers before removing all the images from which those containers were created.</p>\n<p><strong>Windows - Powershell</strong></p>\n<pre class=\"lang-bash prettyprint-override\"><code>docker images -a -q | % { docker image rm $_ -f }\n</code></pre>\n<p><strong>Windows - cmd.exe</strong></p>\n<pre class=\"lang-bash prettyprint-override\"><code>for /F %i in ('docker images -a -q') do docker rmi -f %i\n</code></pre>\n"}, {"owner": {"account_id": 2474337, "reputation": 26012, "user_id": 2155313, "user_type": "registered", "accept_rate": 78, "profile_image": "https://i.sstatic.net/fp9tO.jpg?s=256", "display_name": "errata", "link": "https://stackoverflow.com/users/2155313/errata"}, "is_accepted": true, "score": 2223, "last_activity_date": 1713764548, "last_edit_date": 1713764548, "creation_date": 1432765507, "answer_id": 30494145, "question_id": 30494050, "content_license": "CC BY-SA 4.0", "body": "\n<p>You can pass environment variables to your containers with the <code>-e</code> (alias <code>--env</code>) flag.</p>\n<p><code>docker run -e xx=yy</code></p>\n<p>An example from a startup script:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>sudo docker run -d -t -i -e REDIS_NAMESPACE='staging' \\ \n-e POSTGRES_ENV_POSTGRES_PASSWORD='foo' \\\n-e POSTGRES_ENV_POSTGRES_USER='bar' \\\n-e POSTGRES_ENV_DB_NAME='mysite_staging' \\\n-e POSTGRES_PORT_5432_TCP_ADDR='docker-db-1.hidden.us-east-1.rds.amazonaws.com' \\\n-e SITE_URL='staging.mysite.com' \\\n-p 80:80 \\\n--link redis:redis \\  \n--name container_name dockerhub_id/image_name\n</code></pre>\n<p>Or, if you don't want to have the value on the command-line where it will be displayed by <code>ps</code>, etc., <code>-e</code> can pull in the value from the current environment if you just give it without the <code>=</code>:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>sudo PASSWORD='foo' docker run  [...] -e PASSWORD [...]\n</code></pre>\n<p>If you have many environment variables and especially if they're meant to be secret, you can <a href=\"https://docs.docker.com/reference/cli/docker/container/run/#env\" rel=\"noreferrer\">use an env-file</a>:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ docker run --env-file ./env.list ubuntu bash\n</code></pre>\n<blockquote>\n<p>The --env-file flag takes a filename as an argument and expects each line to be in the VAR=VAL format, mimicking the argument passed to --env. Comment lines need only be prefixed with #</p>\n</blockquote>\n"}, {"owner": {"account_id": 4243, "reputation": 1298440, "user_id": 6309, "user_type": "registered", "accept_rate": 100, "profile_image": "https://i.sstatic.net/I4fiW.jpg?s=256", "display_name": "VonC", "link": "https://stackoverflow.com/users/6309/vonc"}, "is_accepted": true, "score": 1956, "last_activity_date": 1680899934, "last_edit_date": 1680899934, "creation_date": 1442942666, "answer_id": 32723127, "question_id": 32723111, "content_license": "CC BY-SA 4.0", "body": "<h3>(see below for original answer)</h3>\n<hr />\n<p><strong>Update Sept. 2016</strong>: Docker 1.13: <a href=\"https://github.com/docker/docker/pull/26108\" rel=\"noreferrer\">PR 26108</a> and <a href=\"https://github.com/docker/docker/commit/86de7c000f5d854051369754ad1769194e8dd5e1\" rel=\"noreferrer\">commit 86de7c0</a> introduce a few new commands to help facilitate visualizing how much space the docker daemon data is taking on disk and allowing for easily cleaning up &quot;unneeded&quot; excess.</p>\n<p><a href=\"https://docs.docker.com/engine/reference/commandline/system_prune/\" rel=\"noreferrer\"><strong><code>docker system prune</code></strong></a> will delete all dangling data (containers, networks, and images). You can remove all unused volumes with the <code>--volumes</code> option and remove all unused images (not just dangling) with the <code>-a</code> option.</p>\n<p>You also have:</p>\n<ul>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/container_prune/\" rel=\"noreferrer\"><code>docker container prune</code></a></li>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/image_prune/\" rel=\"noreferrer\"><code>docker image prune</code></a></li>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/network_prune/\" rel=\"noreferrer\"><code>docker network prune</code></a></li>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/volume_prune/\" rel=\"noreferrer\"><code>docker volume prune</code></a></li>\n</ul>\n<p>For <em>unused</em> images, use <code>docker image prune -a</code> (for removing dangling <em>and</em> ununsed images).<br />\nWarning: '<em>unused</em>' means &quot;images not referenced by any container&quot;: be careful before using <code>-a</code>.</p>\n<p>As illustrated in <a href=\"https://stackoverflow.com/users/1207596/a-l\">A L</a>'s <a href=\"https://stackoverflow.com/a/50405599/6309\">answer</a>, <code>docker system prune --all</code> will remove all <em>unused</em> images not just dangling ones... which can be a bit too much.</p>\n<p>Combining <code>docker xxx prune</code> with the <a href=\"https://docs.docker.com/engine/reference/commandline/system_prune/#filtering\" rel=\"noreferrer\"><code>--filter</code> option</a> can be a great way to limit the pruning (<a href=\"https://docs.docker.com/develop/sdk/#api-version-matrix\" rel=\"noreferrer\">docker SDK API 1.28 minimum, so docker 17.04+</a>)</p>\n<blockquote>\n<p>The currently supported filters are:</p>\n</blockquote>\n<ul>\n<li><code>until (&lt;timestamp&gt;)</code> - only remove containers, images, and networks created before given timestamp</li>\n<li><code>label</code> (<code>label=&lt;key&gt;</code>, <code>label=&lt;key&gt;=&lt;value&gt;</code>, <code>label!=&lt;key&gt;</code>, or <code>label!=&lt;key&gt;=&lt;value&gt;</code>) - only remove containers, images, networks, and volumes with (or <em>without</em>, in case <code>label!=...</code> is used) the specified labels.</li>\n</ul>\n<p>See &quot;<a href=\"https://docs.docker.com/config/pruning/#prune-images\" rel=\"noreferrer\">Prune images</a>&quot; for an example.</p>\n<hr />\n<p>Warning: there is no &quot;preview&quot; or &quot;<code>--dry-run</code>&quot; option for those <code>docker xxx prune</code> commands.</p>\n<p>This is requested with <a href=\"https://github.com/moby/moby/issues/30623\" rel=\"noreferrer\"><code>moby/moby</code> issue 30623</a> since 2017, but seems <a href=\"https://github.com/moby/moby/issues/30623#issuecomment-1216395952\" rel=\"noreferrer\">tricky to be implemented</a> (Aug. 2022)</p>\n<blockquote>\n<p>Having a more representative overview of what will be pruned will be quite complicated, for various reasons;</p>\n<ul>\n<li><strong>race conditions</strong> (can be resolved by documenting the limitations);<br />\nA container/image/volume/network may not be in use at the time that &quot;dry run&quot; is used, but may be in use the moment the actual prune is executed (or vice-versa), so dry run will always be an &quot;approximation&quot; of what will be pruned.</li>\n<li>the more difficult part is due to <strong>how objects (containers, images, networks etc.) depend on each other</strong>.<br />\nFor example, an image can be deleted if it no longer has references to it (no more tags, no more containers using it); this is the reason that docker system prune deletes objects in a specific order (first remove all unused containers, then remove unused images).<br />\nIn order to replicate the same flow for &quot;dry-run&quot;, it will be needed to temporarily construct representation of all objects and where they're referenced based on that (basically; duplicate all reference-counters, and then remove references from that &quot;shadow&quot; representation).</li>\n<li>Finally; with the <strong>work being done on integrating the <code>containerd</code> snapshotter (image and layer store)</strong>, things may change more;<br />\nFor example, images can now be multi-arch, and (to be discussed), &quot;pruning&quot; could remove unused variants (architectures) from an image to clean up space, which brings another dimension to calculating &quot;what can be removed&quot;.</li>\n</ul>\n</blockquote>\n<hr />\n<h1>Original answer (Sep. 2016)</h1>\n<p>I usually do:</p>\n<pre><code>docker rmi $(docker images --filter &quot;dangling=true&quot; -q --no-trunc)\n</code></pre>\n<p>I have an [alias for removing those <a href=\"https://github.com/docker/docker/blob/634a848b8e3bdd8aed834559f3b2e0dfc7f5ae3a/man/docker-images.1.md#options\" rel=\"noreferrer\">dangling images</a>: <code>drmi</code>]<a href=\"https://github.com/docker/docker/blob/634a848b8e3bdd8aed834559f3b2e0dfc7f5ae3a/man/docker-images.1.md#options\" rel=\"noreferrer\">13</a></p>\n<blockquote>\n<p>The <code>dangling=true</code> filter finds unused images</p>\n</blockquote>\n<p>That way, any intermediate image no longer referenced by a labelled image is removed.</p>\n<p>I do the same <strong>first</strong> for <a href=\"https://github.com/VonC/b2d/blob/b010ab51974ac7de6162cdcbff795d7b9e84fd67/.bash_aliases#L21\" rel=\"noreferrer\">exited processes (containers)</a></p>\n<pre><code>alias drmae='docker rm $(docker ps -qa --no-trunc --filter &quot;status=exited&quot;)'\n</code></pre>\n<p>As <a href=\"https://stackoverflow.com/users/95750/haridsv\">haridsv</a> points out <a href=\"https://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images/32723127#comment63457575_32723127\">in the comments</a>:</p>\n<blockquote>\n<p>Technically, <strong>you should first clean up containers before cleaning up images, as this will catch more dangling images and less errors</strong>.</p>\n</blockquote>\n<hr />\n<p><a href=\"https://github.com/jfrazelle\" rel=\"noreferrer\">Jess Frazelle (jfrazelle)</a> has the <a href=\"https://github.com/jfrazelle/dotfiles/blob/a7fd3df6ab423e6dd04f27727f653753453db837/.dockerfunc#L8-L11\" rel=\"noreferrer\">bashrc function</a>:</p>\n<pre><code>dcleanup(){\n    docker rm -v $(docker ps --filter status=exited -q 2&gt;/dev/null) 2&gt;/dev/null\n    docker rmi $(docker images --filter dangling=true -q 2&gt;/dev/null) 2&gt;/dev/null\n}\n</code></pre>\n<hr />\n<p>To remove old images, and not just &quot;unreferenced-dangling&quot; images, you can consider <a href=\"https://github.com/spotify/docker-gc\" rel=\"noreferrer\"><strong><code>docker-gc</code></strong></a>:</p>\n<hr />\n<blockquote>\n<p>A simple Docker container and image garbage collection script.</p>\n<ul>\n<li>Containers that exited more than an hour ago are removed.</li>\n<li>Images that don't belong to any remaining container after that are removed.</li>\n</ul>\n</blockquote>\n"}, {"owner": {"account_id": 174741, "reputation": 24227, "user_id": 404289, "user_type": "registered", "accept_rate": 71, "profile_image": "https://www.gravatar.com/avatar/1c23303ba42e0f9c0e017a94e900ea6c?s=256&d=identicon&r=PG", "display_name": "vieux", "link": "https://stackoverflow.com/users/404289/vieux"}, "is_accepted": true, "score": 1864, "last_activity_date": 1574931079, "last_edit_date": 1574931079, "creation_date": 1369934111, "answer_id": 16842203, "question_id": 16840409, "content_license": "CC BY-SA 4.0", "body": "<p>To show only <strong>running containers</strong> use the given command:</p>\n\n<pre><code>docker ps\n</code></pre>\n\n<p>To show <strong>all containers</strong> use the given command:</p>\n\n<pre><code>docker ps -a\n</code></pre>\n\n<p>To show the <strong>latest created container</strong> (includes all states) use the given command:</p>\n\n<pre><code>docker ps -l\n</code></pre>\n\n<p>To show <strong>n last created containers</strong> (includes all states) use the given command:</p>\n\n<pre><code>docker ps -n=-1\n</code></pre>\n\n<p>To display <strong>total file sizes</strong> use the given command:</p>\n\n<pre><code>docker ps -s\n</code></pre>\n\n<p>The content presented above is from <a href=\"https://docs.docker.com/v1.11/engine/reference/commandline/ps/\" rel=\"noreferrer\">docker.com</a>.</p>\n\n<p>In the new version of Docker, commands are updated, and some management commands are added:</p>\n\n<pre><code>docker container ls\n</code></pre>\n\n<p>It is used to list all the running containers.</p>\n\n<pre><code>docker container ls -a\n</code></pre>\n\n<p>And then, if you want to clean them all,</p>\n\n<pre><code>docker rm $(docker ps -aq)\n</code></pre>\n\n<p>It is used to list all the containers created irrespective of its state.</p>\n\n<p>And to stop all the Docker containers (force)</p>\n\n<pre><code>docker rm -f $(docker ps -a -q)  \n</code></pre>\n\n<p>Here the container is the management command.</p>\n"}, {"owner": {"account_id": 146372, "reputation": 76897, "user_id": 356788, "user_type": "registered", "accept_rate": 43, "profile_image": "https://www.gravatar.com/avatar/5b5661a3a443a2a4bece8674006bd6ef?s=256&d=identicon&r=PG", "display_name": "Ken Cochrane", "link": "https://stackoverflow.com/users/356788/ken-cochrane"}, "is_accepted": true, "score": 1810, "last_activity_date": 1562657029, "last_edit_date": 1562657029, "creation_date": 1371824751, "answer_id": 17237701, "question_id": 17236796, "content_license": "CC BY-SA 4.0", "body": "<p>Since <a href=\"https://github.com/moby/moby/blob/master/CHANGELOG.md#1130-2017-01-18\" rel=\"noreferrer\">Docker 1.13.x</a> you can use <a href=\"https://docs.docker.com/engine/reference/commandline/container_prune/\" rel=\"noreferrer\">Docker container prune</a>:</p>\n\n<pre><code>docker container prune\n</code></pre>\n\n<p>This will remove all stopped containers and should work on all platforms the same way.</p>\n\n<p>There is also a <a href=\"https://docs.docker.com/engine/reference/commandline/system_prune/\" rel=\"noreferrer\">Docker system prune</a>:</p>\n\n<pre><code>docker system prune\n</code></pre>\n\n<p>which will clean up all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes, in one command.</p>\n\n<hr>\n\n<p>For older Docker versions, you can string Docker commands together with other Unix commands to get what you need. Here is an example on how to clean up old containers that are weeks old:</p>\n\n<pre><code>$ docker ps --filter \"status=exited\" | grep 'weeks ago' | awk '{print $1}' | xargs --no-run-if-empty docker rm\n</code></pre>\n\n<p>To give credit, where it is due, this example is from <a href=\"https://twitter.com/jpetazzo/status/347431091415703552\" rel=\"noreferrer\">https://twitter.com/jpetazzo/status/347431091415703552</a>.</p>\n"}, {"owner": {"account_id": 1562447, "reputation": 37732, "user_id": 1452016, "user_type": "registered", "profile_image": "https://i.sstatic.net/Ssf3P.jpg?s=256", "display_name": "Andy", "link": "https://stackoverflow.com/users/1452016/andy"}, "is_accepted": true, "score": 1648, "last_activity_date": 1576909590, "last_edit_date": 1576909590, "creation_date": 1407545430, "answer_id": 25214186, "question_id": 25211198, "content_license": "CC BY-SA 4.0", "body": "<pre><code>docker image tag server:latest myname/server:latest\n</code></pre>\n\n<p>or</p>\n\n<pre><code>docker image tag d583c3ac45fd myname/server:latest\n</code></pre>\n\n<p>Tags are just human-readable aliases for the full image name (<code>d583c3ac45fd...</code>). </p>\n\n<p>So you can have as many of them associated with the same image as you like. If you don't like the old name you can remove it after you've retagged it:</p>\n\n<pre><code>docker rmi server\n</code></pre>\n\n<p>That will just remove the <code>alias/tag</code>. Since <code>d583c3ac45fd</code> has other names, the actual image won't be deleted.</p>\n"}, {"owner": {"account_id": 451260, "reputation": 31435, "user_id": 847064, "user_type": "registered", "accept_rate": 84, "profile_image": "https://www.gravatar.com/avatar/e7c3430a01629f9ca6d3bcb847e8e3b2?s=256&d=identicon&r=PG", "display_name": "Thomas Uhrig", "link": "https://stackoverflow.com/users/847064/thomas-uhrig"}, "is_accepted": true, "score": 1632, "last_activity_date": 1508521317, "last_edit_date": 1508521317, "creation_date": 1400499601, "answer_id": 23736802, "question_id": 23735149, "content_license": "CC BY-SA 3.0", "body": "<p>An instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.</p>\n\n<p>You can see all your images with <code>docker images</code> whereas you can see your running containers with <code>docker ps</code> (and you can see all containers with <code>docker ps -a</code>).</p>\n\n<p>So a running instance of an image is a container.</p>\n"}, {"owner": {"account_id": 3169080, "reputation": 20537, "user_id": 2678466, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/2183a9383a1cd4056b4f5298cb8da5fc?s=256&d=identicon&r=PG&f=y&so-version=2", "display_name": "Solomon Hykes", "link": "https://stackoverflow.com/users/2678466/solomon-hykes"}, "is_accepted": false, "score": 1497, "last_activity_date": 1541708557, "last_edit_date": 1541708557, "creation_date": 1394691379, "answer_id": 22370529, "question_id": 16647069, "content_license": "CC BY-SA 4.0", "body": "<p>I'm the author of Docker.</p>\n\n<p>The short answer is that if you want to manage machines, you should use Vagrant. And if you want to build and run applications environments, you should use Docker.</p>\n\n<p>Vagrant is a tool for managing virtual machines. Docker is a tool for building and deploying applications by packaging them into lightweight containers. A container can hold pretty much any software component along with its dependencies (executables, libraries, configuration files, etc.), and execute it in a guaranteed and repeatable runtime environment. This makes it very easy to build your app once and deploy it anywhere - on your laptop for testing, then on different servers for live deployment, etc.</p>\n\n<p>It's a common misconception that you can only use Docker on Linux. That's incorrect; you can also install Docker on Mac, and Windows. When installed on Mac, Docker bundles a tiny Linux VM (25&nbsp;MB on disk!) which acts as a wrapper for your container. Once installed this is completely transparent; you can use the Docker command-line in exactly the same way. This gives you the best of both worlds: you can test and develop your application using containers, which are very lightweight, easy to test and easy to move around (see for example <a href=\"https://hub.docker.com\" rel=\"noreferrer\">https://hub.docker.com</a> for sharing reusable containers with the Docker community), and you don't need to worry about the nitty-gritty details of managing virtual machines, which are just a means to an end anyway.</p>\n\n<p>In theory it's possible to use Vagrant as an abstraction layer for Docker. I recommend against this for two reasons:</p>\n\n<ul>\n<li><p>First, Vagrant is not a good abstraction for Docker. Vagrant was designed to manage virtual machines. Docker was designed to manage an application runtime. This means that Docker, by design, can interact with an application in richer ways, and has more information about the application runtime. The primitives in Docker are processes, log streams, environment variables, and network links between components. The primitives in Vagrant are machines, block devices, and ssh keys. Vagrant simply sits lower in the stack, and the only way it can interact with a container is by pretending it's just another kind of machine, that you can \"boot\" and \"log into\". So, sure, you can type \"vagrant up\" with a Docker plugin and something pretty will happen. Is it a substitute for the full breadth of what Docker can do? Try native Docker for a couple days and see for yourself :)</p></li>\n<li><p>Second, the lock-in argument. \"If you use Vagrant as an abstraction, you will not be locked into Docker!\". From the point of view of Vagrant, which is designed to manage machines, this makes perfect sense: aren't containers just another kind of machine? Just like Amazon EC2 and VMware, we must be careful not to tie our provisioning tools to any particular vendor! This would create lock-in - better to abstract it all away with Vagrant. Except this misses the point of Docker entirely. Docker doesn't provision machines; it wraps your application in a lightweight portable runtime which can be dropped anywhere.</p></li>\n</ul>\n\n<p>What runtime you choose for your application has nothing to do with how you provision your machines! For example it's pretty frequent to deploy applications to machines which are provisioned by someone else (for example an EC2 instance deployed by your system administrator, perhaps using Vagrant), or to bare metal machines which Vagrant can't provision at all. Conversely, you may use Vagrant to provision machines which have nothing to do with developing your application - for example a ready-to-use Windows IIS box or something. Or you may use Vagrant to provision machines for projects which don't use Docker - perhaps they use a combination of rubygems and rvm for dependency management and sandboxing for example.</p>\n\n<p>In summary: Vagrant is for managing machines, and Docker is for building and running application environments.</p>\n"}, {"owner": {"account_id": 3053705, "reputation": 26778, "user_id": 2587797, "user_type": "registered", "accept_rate": 44, "profile_image": "https://i.sstatic.net/8H6jK.png?s=256", "display_name": "RustyShackleford", "link": "https://stackoverflow.com/users/2587797/rustyshackleford"}, "is_accepted": true, "score": 1495, "last_activity_date": 1562876665, "last_edit_date": 1562876665, "creation_date": 1430864213, "answer_id": 30064175, "question_id": 30063907, "content_license": "CC BY-SA 4.0", "body": "<p>Figured it out, use <strong><code>bash -c</code></strong>.</p>\n\n<p>Example:</p>\n\n<pre><code>command: bash -c \"python manage.py migrate &amp;&amp; python manage.py runserver 0.0.0.0:8000\"\n</code></pre>\n\n<p>Same example in multilines:</p>\n\n<pre><code>command: &gt;\n    bash -c \"python manage.py migrate\n    &amp;&amp; python manage.py runserver 0.0.0.0:8000\"\n</code></pre>\n\n<p>Or:</p>\n\n<pre><code>command: bash -c \"\n    python manage.py migrate\n    &amp;&amp; python manage.py runserver 0.0.0.0:8000\n  \"\n</code></pre>\n"}, {"owner": {"account_id": 7752137, "reputation": 38521, "user_id": 5867722, "user_type": "registered", "profile_image": "https://i.sstatic.net/dROn5.jpg?s=256", "display_name": "Farhad Farahi", "link": "https://stackoverflow.com/users/5867722/farhad-farahi"}, "is_accepted": true, "score": 1437, "last_activity_date": 1694867295, "last_edit_date": 1694867295, "creation_date": 1475772090, "answer_id": 39901446, "question_id": 39901311, "content_license": "CC BY-SA 4.0", "body": "<p>Docker images are pretty minimal, but you can install <code>ping</code> in your official ubuntu docker image via:</p>\n\n<pre class=\"lang-bash prettyprint-override\"><code>apt-get update -y\napt-get install -y iputils-ping\n</code></pre>\n<p>Chances are you don't need <code>ping</code> on your image, and just want to use it for testing purposes. Above example will help you out.</p>\n<p>But if you need <code>ping</code> to exist on your image, you can create a <code>Dockerfile</code> or <code>commit</code> the container you ran the above commands into a new image.</p>\n<p>Commit:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>docker commit -m &quot;Installed iputils-ping&quot; --author &quot;Your Name &lt;name@domain.com&gt;&quot; ContainerNameOrId yourrepository/imagename:tag\n</code></pre>\n<p>Dockerfile:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>FROM ubuntu\nRUN apt-get update &amp;&amp; apt-get install -y iputils-ping\nCMD bash\n</code></pre>\n<p>Please note there are best practices on creating docker images, like clearing apt cache files afterwards and etc.</p>\n"}, {"recommendations": [{"collective": {"tags": ["continuous-delivery", "circleci", "bitbucket-pipelines", "gitlab-ci-runner", "tfsbuild", "continuous-testing", "hudson", "argocd", "jenkins", "github-actions", "jenkins-groovy", "azure-pipelines", "continuous-deployment", "teamcity", "google-cloud-build", "gitlab-ci", "jenkins-pipeline", "codemagic", "cicd", "octopus-deploy", "jenkins-plugins", "continuous-integration"], "external_links": [{"type": "support", "link": "https://stackoverflow.com/contact?topic=15"}], "description": "A collective where developers focused on continuous integration, delivery, and deployment can find, share, and learn about simultaneous development.", "link": "/collectives/ci-cd", "name": "CI/CD", "slug": "ci-cd"}, "creation_date": 1677493674}], "owner": {"account_id": 293130, "reputation": 257208, "user_id": 596285, "user_type": "registered", "accept_rate": 100, "profile_image": "https://www.gravatar.com/avatar/b6975c494d3d9c404dd3d7af2edf3133?s=256&d=identicon&r=PG", "display_name": "BMitch", "link": "https://stackoverflow.com/users/596285/bmitch"}, "is_accepted": true, "score": 1376, "last_activity_date": 1611589101, "last_edit_date": 1611589101, "creation_date": 1490805072, "answer_id": 43099210, "question_id": 43099116, "content_license": "CC BY-SA 4.0", "body": "<p>Remove the <code>-it</code> from your cli to make it non interactive and remove the TTY. If you don't need either, e.g. running your command inside of a Jenkins or cron script, you should do this.</p>\n<p>Or you can change it to <code>-i</code> if you have input piped into the docker command that doesn't come from a TTY. If you have something like <code>xyz | docker ...</code> or <code>docker ... &lt;input</code> in your command line, do this.</p>\n<p>Or you can change it to <code>-t</code> if you want TTY support but don't have it available on the input device. Do this for apps that check for a TTY to enable color formatting of the output in your logs, or for when you later attach to the container with a proper terminal.</p>\n<p>Or if you need an interactive terminal and aren't running in a terminal on Linux or MacOS, use a different command line interface. PowerShell is reported to include this support on Windows.</p>\n<hr />\n<p>What is a TTY? It's a terminal interface that supports escape sequences, moving the cursor around, etc, that comes from the old days of dumb terminals attached to mainframes. Today it is provided by the Linux command terminals and ssh interfaces. See the <a href=\"https://en.wikipedia.org/wiki/Terminal_emulator\" rel=\"noreferrer\">wikipedia article for more details</a>.</p>\n<p>To see the difference of running a container with and without a TTY, run a container without one: <code>docker run --rm -i ubuntu bash</code>. From inside that container, install vim with <code>apt-get update; apt-get install vim</code>. Note the lack of a prompt. When running vim against a file, try to move the cursor around within the file.</p>\n"}, {"owner": {"account_id": 2656817, "reputation": 34210, "user_id": 2297345, "user_type": "registered", "accept_rate": 55, "profile_image": "https://i.sstatic.net/srFBt.jpg?s=256", "display_name": "Michael_Scharf", "link": "https://stackoverflow.com/users/2297345/michael-scharf"}, "is_accepted": true, "score": 1329, "last_activity_date": 1615329199, "last_edit_date": 1615329199, "creation_date": 1413927650, "answer_id": 26496854, "question_id": 20932357, "content_license": "CC BY-SA 4.0", "body": "<p>With docker 1.3, there is a new command <a href=\"https://docs.docker.com/engine/reference/commandline/exec/\" rel=\"noreferrer\"><code>docker exec</code></a>. This allows you to enter a running container:</p>\n<pre><code>docker exec -it [container-id] bash\n</code></pre>\n<p><strong>Note:</strong> this assumes <code>bash</code> is installed on your container. You may run <code>sh</code> or whatever interactive shell is installed on the container.</p>\n"}, {"owner": {"account_id": 5110015, "reputation": 13925, "user_id": 4096935, "user_type": "registered", "accept_rate": 100, "profile_image": "https://graph.facebook.com/100001603122463/picture?type=large", "display_name": "Webert Lima", "link": "https://stackoverflow.com/users/4096935/webert-lima"}, "is_accepted": true, "score": 1298, "last_activity_date": 1583333135, "last_edit_date": 1583333135, "creation_date": 1485966165, "answer_id": 41984666, "question_id": 41984399, "content_license": "CC BY-SA 4.0", "body": "<p>You may need to switch your docker repo to private before docker push.</p>\n\n<p>Thanks to the <a href=\"https://stackoverflow.com/a/42403423/4096935\">answer</a> provided by <a href=\"https://stackoverflow.com/users/7607604/dean-wu\">Dean Wu</a> and <a href=\"https://stackoverflow.com/questions/41984399/denied-requested-access-to-the-resource-is-denied-docker/41984666#comment94770203_41984666\">this comment</a> by <a href=\"https://stackoverflow.com/users/369759/ses\">ses</a>, before pushing, remember to <strong>log out</strong>, then <strong>log in</strong> from the command line to your docker hub account</p>\n\n<pre><code># you may need log out first `docker logout` ref. https://stackoverflow.com/a/53835882/248616\ndocker login\n</code></pre>\n\n<p>According to the <a href=\"https://docs.docker.com/engine/getstarted/step_six/#/step-1-tag-and-push-the-image\" rel=\"noreferrer\">docs</a>:</p>\n\n<pre><code>You need to include the namespace for Docker Hub to associate it with your account.\nThe namespace is the same as your Docker Hub account name.\nYou need to rename the image to YOUR_DOCKERHUB_NAME/docker-whale.\n</code></pre>\n\n<p>So, this means you have to <strong>tag</strong> your image before pushing:</p>\n\n<pre><code>docker tag firstimage YOUR_DOCKERHUB_NAME/firstimage\n</code></pre>\n\n<p>and then you should be able to push it.</p>\n\n<pre><code>docker push YOUR_DOCKERHUB_NAME/firstimage\n</code></pre>\n"}, {"owner": {"account_id": 2277663, "reputation": 13909, "user_id": 2003537, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/70b786b2c3d9110294a9612fa3123d22?s=256&d=identicon&r=PG", "display_name": "Daishi", "link": "https://stackoverflow.com/users/2003537/daishi"}, "is_accepted": false, "score": 1254, "last_activity_date": 1449958654, "creation_date": 1449958654, "answer_id": 34245657, "question_id": 21553353, "content_license": "CC BY-SA 3.0", "body": "<p>The <code>ENTRYPOINT</code> specifies a command that will always be executed when the container starts.</p>\n\n<p>The <code>CMD</code> specifies arguments that will be fed to the <code>ENTRYPOINT</code>.</p>\n\n<p>If you want to make an image dedicated to a specific command you will use <code>ENTRYPOINT [\"/path/dedicated_command\"]</code></p>\n\n<p>Otherwise, if you want to make an image for general purpose, you can leave <code>ENTRYPOINT</code> unspecified and use <code>CMD [\"/path/dedicated_command\"]</code> as you will be able to override the setting by supplying arguments to <code>docker run</code>.</p>\n\n<p>For example, if your Dockerfile is:</p>\n\n<pre><code>FROM debian:wheezy\nENTRYPOINT [\"/bin/ping\"]\nCMD [\"localhost\"]\n</code></pre>\n\n<p>Running the image without any argument will ping the localhost:</p>\n\n<pre><code>$ docker run -it test\nPING localhost (127.0.0.1): 48 data bytes\n56 bytes from 127.0.0.1: icmp_seq=0 ttl=64 time=0.096 ms\n56 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.088 ms\n56 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.088 ms\n^C--- localhost ping statistics ---\n3 packets transmitted, 3 packets received, 0% packet loss\nround-trip min/avg/max/stddev = 0.088/0.091/0.096/0.000 ms\n</code></pre>\n\n<p>Now, running the image with an argument will ping the argument:</p>\n\n<pre><code>$ docker run -it test google.com\nPING google.com (173.194.45.70): 48 data bytes\n56 bytes from 173.194.45.70: icmp_seq=0 ttl=55 time=32.583 ms\n56 bytes from 173.194.45.70: icmp_seq=2 ttl=55 time=30.327 ms\n56 bytes from 173.194.45.70: icmp_seq=4 ttl=55 time=46.379 ms\n^C--- google.com ping statistics ---\n5 packets transmitted, 3 packets received, 40% packet loss\nround-trip min/avg/max/stddev = 30.327/36.430/46.379/7.095 ms\n</code></pre>\n\n<p>For comparison, if your Dockerfile is:</p>\n\n<pre><code>FROM debian:wheezy\nCMD [\"/bin/ping\", \"localhost\"]\n</code></pre>\n\n<p>Running the image without any argument will ping the localhost:</p>\n\n<pre><code>$ docker run -it test\nPING localhost (127.0.0.1): 48 data bytes\n56 bytes from 127.0.0.1: icmp_seq=0 ttl=64 time=0.076 ms\n56 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.087 ms\n56 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.090 ms\n^C--- localhost ping statistics ---\n3 packets transmitted, 3 packets received, 0% packet loss\nround-trip min/avg/max/stddev = 0.076/0.084/0.090/0.000 ms\n</code></pre>\n\n<p>But running the image with an argument will run the argument:</p>\n\n<pre><code>docker run -it test bash\nroot@e8bb7249b843:/#\n</code></pre>\n\n<p>See this article from Brian DeHamer for even more details:\n<a href=\"https://www.ctl.io/developers/blog/post/dockerfile-entrypoint-vs-cmd/\">https://www.ctl.io/developers/blog/post/dockerfile-entrypoint-vs-cmd/</a></p>\n"}, {"owner": {"account_id": 903697, "reputation": 12643, "user_id": 939125, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/4bfda429768d89520c91c809eaab1577?s=256&d=identicon&r=PG", "display_name": "Homme Zwaagstra", "link": "https://stackoverflow.com/users/939125/homme-zwaagstra"}, "is_accepted": true, "score": 1215, "last_activity_date": 1719326759, "last_edit_date": 1719326759, "creation_date": 1470224395, "answer_id": 38742545, "question_id": 27093612, "content_license": "CC BY-SA 4.0", "body": "<p>You can use <a href=\"https://docs.docker.com/engine/reference/builder/#environment-replacement\" rel=\"noreferrer\">Environment Replacement</a> in your <code>Dockerfile</code> as follows:</p>\n<pre><code>ENV PATH=&quot;$PATH:/opt/gtk/bin&quot;\n</code></pre>\n<p>(please note that when using ${PATH}, this might use the host's PATH instead of the Container)</p>\n"}, {"owner": {"account_id": 37442, "reputation": 102557, "user_id": 107049, "user_type": "registered", "accept_rate": 75, "profile_image": "https://www.gravatar.com/avatar/b1f458499807b5dbd4019bfc9714f644?s=256&d=identicon&r=PG", "display_name": "Thomasleveil", "link": "https://stackoverflow.com/users/107049/thomasleveil"}, "is_accepted": true, "score": 1191, "last_activity_date": 1696715802, "last_edit_date": 1696715802, "creation_date": 1413972194, "answer_id": 26504961, "question_id": 26504846, "content_license": "CC BY-SA 4.0", "body": "<pre><code>ADD go /usr/local/\n</code></pre>\n<p>will copy the <strong><a href=\"https://docs.docker.com/engine/reference/builder/#copy\" rel=\"noreferrer\">contents</a></strong> of your local <code>go</code> directory into the <code>/usr/local/</code> directory of your docker image.</p>\n<p>To copy the <code>go</code> directory itself in <code>/usr/local/</code> use:</p>\n<pre><code>ADD go /usr/local/go\n</code></pre>\n<p>or</p>\n<pre><code>COPY go /usr/local/go\n</code></pre>\n"}, {"owner": {"account_id": 474951, "reputation": 120344, "user_id": 884978, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/bdb4f5f287976278b6e02f66e85c41dc?s=256&d=identicon&r=PG", "display_name": "creack", "link": "https://stackoverflow.com/users/884978/creack"}, "is_accepted": true, "score": 1188, "last_activity_date": 1482620889, "last_edit_date": 1482620889, "creation_date": 1369586770, "answer_id": 16761439, "question_id": 16647069, "content_license": "CC BY-SA 3.0", "body": "<p>If your purpose is the isolation, I think Docker is what you want.</p>\n\n<p>Vagrant is a virtual machine manager. It allows you to script the virtual machine configuration as well as the provisioning. However, it is still a virtual machine depending on <a href=\"http://en.wikipedia.org/wiki/VirtualBox\">VirtualBox</a> (or others) with a huge overhead. It requires you to have a hard drive file that can be huge, it takes a lot of ram, and performance may be not very good.</p>\n\n<p>Docker on the other hand uses kernel cgroup and namespacing via <a href=\"https://en.wikipedia.org/wiki/LXC\">LXC</a>. It means that you are using the same kernel as the host and the same file system.\nYou can use Dockerfile with the <code>docker build</code> command in order to handle the provisioning and configuration of your container. You have an example at <a href=\"https://docs.docker.com/\">docs.docker.com</a> on how to make your Dockerfile; it is very intuitive.</p>\n\n<p>The only reason you could want to use Vagrant is if you need to do BSD, Windows or other non-Linux development on your Ubuntu box. Otherwise, go for Docker.</p>\n"}, {"owner": {"account_id": 122334, "reputation": 11504, "user_id": 316075, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/46000b57cd0420e1724756b6284cd17e?s=256&d=identicon&r=PG", "display_name": "Tania Ang", "link": "https://stackoverflow.com/users/316075/tania-ang"}, "is_accepted": true, "score": 1123, "last_activity_date": 1408661185, "last_edit_date": 1408661185, "creation_date": 1388462274, "answer_id": 20851484, "question_id": 20845056, "content_license": "CC BY-SA 3.0", "body": "<p>To expose just one port, this is what you need to do:</p>\n\n<pre><code>docker run -p &lt;host_port&gt;:&lt;container_port&gt;\n</code></pre>\n\n<p>To expose multiple ports, simply provide multiple <code>-p</code> arguments:</p>\n\n<pre><code>docker run -p &lt;host_port1&gt;:&lt;container_port1&gt; -p &lt;host_port2&gt;:&lt;container_port2&gt;\n</code></pre>\n"}], "has_more": true, "quota_max": 300, "quota_remaining": 289}